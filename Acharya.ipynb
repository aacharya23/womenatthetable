{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46981dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Install packages \n",
    "!pip install aif360;\n",
    "!pip install fairlearn;\n",
    "!pip install 'aif360[AdversarialDebiasing]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Install packages to fetch data \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.sklearn.datasets import fetch_compas\n",
    "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
    "\n",
    "from aif360.sklearn.preprocessing import ReweighingMeta\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, average_odds_error, generalized_fpr, average_odds_difference\n",
    "from aif360.sklearn.metrics import generalized_fnr, difference, statistical_parity_difference, equal_opportunity_difference, generalized_entropy_error\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be00e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data = pd.read_csv(\"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-raw.csv\")\n",
    "#Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Confusion matrix and Visualisation plots, creating function for later \n",
    "\n",
    "# Function for visualising the confusion matrix and other statistics\n",
    "# https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n",
    "\n",
    "def make_confusion_matrix(cf_matrix, model):\n",
    "  group_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\n",
    "  group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                  cf_matrix.flatten()]\n",
    "  group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "  group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "  group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf_matrix.flatten()]\n",
    "  group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "  box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "  box_labels = np.asarray(box_labels).reshape(cf_matrix.shape[0],cf_matrix.shape[1])\n",
    "\n",
    "\n",
    "  # add more statistics\n",
    "  accuracy  = np.trace(cf_matrix) / float(np.sum(cf_matrix))\n",
    "  precision = cf_matrix[1,1] / sum(cf_matrix[:,1])\n",
    "  recall    = cf_matrix[1,1] / sum(cf_matrix[1,:])\n",
    "  f1_score  = 2*precision*recall / (precision + recall)\n",
    "  stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "      accuracy,precision,recall,f1_score)\n",
    "\n",
    "\n",
    "  categories=[\"Low score\", \"High score\"]\n",
    "  sns.heatmap(cf_matrix,annot=box_labels,fmt=\"\",cmap='Purples',xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label' + stats_text)\n",
    "  plt.title(f\"Confusion matrix and statistics for the {model} model\");\n",
    "\n",
    "## defining function for displaying metrics of training and test data by sex \n",
    "def metrics_per_group(y_test, y_pred):\n",
    "\t# y true per group\n",
    "\ty_test_male = y_test.loc[y_test.index.get_level_values(1) == 1]\n",
    "\ty_test_female = y_test.loc[y_test.index.get_level_values(1) == 0]\n",
    "\n",
    "\t# y_pred per group\n",
    "\ty_pred_male = y_pred[y_test.index.get_level_values(1) == 1]\n",
    "\ty_pred_female = y_pred[y_test.index.get_level_values(1) == 0]\n",
    "\n",
    "\t# metrics\n",
    "\tscores = []\n",
    "\tscores.append(accuracy_score(y_test, y_pred))\n",
    "\tscores.append(recall_score(y_test, y_pred))\n",
    "\tscores.append(precision_score(y_test, y_pred))\n",
    "\n",
    "\tscores.append(accuracy_score(y_test_female, y_pred_female))\n",
    "\tscores.append(recall_score(y_test_female, y_pred_female))\n",
    "\tscores.append(precision_score(y_test_female, y_pred_female))\n",
    "\n",
    "\tscores.append(accuracy_score(y_test_male, y_pred_male))\n",
    "\tscores.append(recall_score(y_test_male, y_pred_male))\n",
    "\tscores.append(precision_score(y_test_male, y_pred_male))\n",
    "\n",
    "\tattribute = [\"all\"]*3 + [\"female\"] *3 + [\"male\"] *3\n",
    "\tmetric = [\"accuracy\", \"recall\", \"precision\"] * 3\n",
    "\t  \n",
    "\t# dictionary of lists \n",
    "\tdict = {'gender': attribute, 'metrics': metric, 'score': scores} \n",
    "\t    \n",
    "\tdf = pd.DataFrame(dict)\n",
    "\n",
    "\tsns.barplot(x = \"metrics\", y = \"score\", hue = \"gender\", data = df, palette = ['#dfcd1a', '#9d0677', '#236c48'])\n",
    "\tplt.title(\"Performance metrics by groups\")\n",
    " \n",
    "\n",
    "def plot_fair_metrics(fair_metrics_mitigated, model): \n",
    "  cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'generalized_entropy']\n",
    "  obj_fairness = [[0,0,1]]\n",
    "\n",
    "  # row for objectives    \n",
    "  fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "      \n",
    "  # row for baseline model\n",
    "  fair_metrics.loc['Baseline Model'] = [stat_par_diff, eq_opp_diff, gen_entr_error]\n",
    "\n",
    "  # row for mitigated bias\n",
    "  fair_metrics.loc[model] = fair_metrics_mitigated\n",
    "\n",
    "\n",
    "  metrics_len = len(cols)\n",
    "\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(20,4), ncols=metrics_len, nrows=1)\n",
    "\n",
    "  plt.subplots_adjust(\n",
    "      left    =  0.125, \n",
    "      bottom  =  0.1, \n",
    "      right   =  0.9, \n",
    "      top     =  0.9, \n",
    "      wspace  =  .5, \n",
    "      hspace  =  1.1\n",
    "  )\n",
    "\n",
    "  y_title_margin = 1.2\n",
    "\n",
    "  plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "  sns.set(style=\"dark\")\n",
    "\n",
    "  cols = fair_metrics.columns.values\n",
    "  obj = fair_metrics.loc['objective']\n",
    "  size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "  rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "  bottom = [-1,-1,-1,0,0]\n",
    "  top = [1,1,1,2,1]\n",
    "  bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "  for i in range(0,metrics_len):\n",
    "      plt.subplot(1, metrics_len, i+1)\n",
    "      ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "      \n",
    "      for j in range(0,len(fair_metrics)-1):\n",
    "          a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "          marg = -0.2 if val < 0 else 0.1\n",
    "          ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "      plt.ylim(bottom[i], top[i])\n",
    "      plt.setp(ax.patches, linewidth=0)\n",
    "      ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "      plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "      plt.title(cols[i])\n",
    "      ax.set_ylabel('')    \n",
    "      ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In machine learning tasks, specifically with supervised learning, you have features and labels. \n",
    "## The features are the descriptive attributes (they are defined as X), and the label (y) is what you're attempting to predict or forecast\n",
    "\n",
    "X, y = fetch_compas()\n",
    "# print(f'There are {X.shape[0]} entries and {X.shape[1]} features')\n",
    "X.head()\n",
    "#y.head()\n",
    "#X.index\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index = pd.MultiIndex.from_arrays(X.index.codes, names=X.index.names)\n",
    "y.index = pd.MultiIndex.from_arrays(y.index.codes, names=y.index.names)\n",
    "# 0 is Male, 1 is Female\n",
    "# 5 is Other, 0 is African American, 1 is Asian, 2 is Caucasian, 3 is Hispanic, 4 is Native American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afba6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target class to 0/1\n",
    "y = pd.Series(y.factorize(sort=True)[0], index=y.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617cbcb",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22eaae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = X.copy()\n",
    "df_viz['sex'] = X['sex'].replace({1.0: 'Female', 0.0: 'Male'})\n",
    "df_viz['c_charge_degree'] = y.replace({1:'M', 0: 'F'})\n",
    "df_viz.index = df_viz.index.droplevel('sex')\n",
    "\n",
    "purple = '#9d0677'\n",
    "green = '#30875c'\n",
    "workshop_palette = [purple, green]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='c_charge_degree', data=df_viz, palette=workshop_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y=\"race\", data=df_viz, palette=[\"#30875c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bfad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_counts = (df_viz.groupby(['sex'])['race']\n",
    "                     .value_counts(normalize=True)\n",
    "                     .rename('percentage')\n",
    "                     .mul(100)\n",
    "                     .reset_index()\n",
    "                     .sort_values('race'))\n",
    "p = sns.barplot(y=\"race\", x=\"percentage\", hue=\"sex\", data=race_counts, palette=workshop_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f37174",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sex = sns.countplot(x=\"age_cat\", hue=\"sex\", data=df_viz, palette=workshop_palette)\n",
    "\n",
    "plt.title('Age Category Distribution by sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d3956",
   "metadata": {},
   "source": [
    "# Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec282f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create dummies\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234567)\n",
    "\n",
    "# one-hoy encode the categorical features\n",
    "data_preproc = make_column_transformer(\n",
    "        (OneHotEncoder(sparse=False, handle_unknown='ignore'), X_train.dtypes == 'category'))\n",
    "\n",
    "X_train = pd.DataFrame(data_preproc.fit_transform(X_train), index=X_train.index)\n",
    "X_test = pd.DataFrame(data_preproc.transform(X_test), index=X_test.index)\n",
    "\n",
    "# to save the information for the column names\n",
    "pd.get_dummies(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daea1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.sklearn.preprocessing import ReweighingMeta, Reweighing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_roc_curve, recall_score, precision_score\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "reg = lr.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "acc_base = accuracy_score(y_test, y_pred)\n",
    "print(f'[Baseline] The test accuracy of the algorithm is: {acc_base: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914290ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sex predicting score \n",
    "##Look at 2nd column of matrix for precision \n",
    "##2nd row of matrix for recall \n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "make_confusion_matrix(cf_matrix, \"[Baseline]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12acc9c",
   "metadata": {},
   "source": [
    "Accuracy: What proportion of predictions does the model classify correctly?\n",
    "\n",
    "The model correctly predicts the score as high or low 60.8% of the time.\n",
    "\n",
    "Precision: What proportion of positive identifications are actually correct?\n",
    "\n",
    "When the model predicts a high score, it is correct 58% of the time. \n",
    "\n",
    "Recall: What proportion of actual positives are identified correctly?\n",
    "\n",
    "The model identifies 50% of all actual high scores. \n",
    "\n",
    "The F1 score of 0.537, a combination of precision and recall, shows that the model is just above mediocre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc16a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_group(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660fdc18",
   "metadata": {},
   "source": [
    "In the case of accuracy and precision, the metrics are fairly similar across genders. The model correctly predicts the score for males slightly more frequently than females (accuracy). However, when the model predicts a high score, it is correct slightly less frequently for males than females (precision). In terms of recall, the recall score for males is significantly lower than that for females or the combined population. The model identifies only about 20% of the actual high scores for males, as opposed to ~ 55% for females and 50% overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b89bb3",
   "metadata": {},
   "source": [
    "Statistical Parity Difference is computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group. It essentially equalizes the outcomes across the protected and non-protected groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_par_diff = statistical_parity_difference(y_test, prot_attr='sex')\n",
    "\n",
    "print(f'[Baseline] The statistical parity difference is {stat_par_diff: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548b875",
   "metadata": {},
   "source": [
    "The difference between the rate of favorable outcomes received by the unprivileged group to the privileged group is 0.14. The value is positive and high, indicating that it is favorable for the unprivileged group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d25ffc",
   "metadata": {},
   "source": [
    "Generalized entropy error \n",
    "\n",
    "Generalized entropy index is proposed as a unified individual and group fairness measure. It measures the inequality in benefit allocation for individuals.\n",
    "A value of 0 implies perfect fairness.\n",
    "Fairness is indicated by lower scores, higher scores are problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5671103",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_entr_error = generalized_entropy_error(y_test, y_pred, alpha=1)\n",
    "\n",
    "print(f'[Baseline] The generalized entropy error is {gen_entr_error: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268b7a3",
   "metadata": {},
   "source": [
    "This is a high entropy value, indicating that using this individual fairness metric the model is very unfair. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3acfe",
   "metadata": {},
   "source": [
    "Equal Opportunity Difference This metric is computed as the difference of true positive rates between the unprivileged and the privileged groups. The true positive rate is the ratio of true positives to the total number of actual positives for a given group.\n",
    "The ideal value is 0. A value of < 0 implies higher benefit for the privileged group and a value > 0 implies higher benefit for the unprivileged group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb780642",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "eq_opp_diff = equal_opportunity_difference(y_test, y_pred, prot_attr='sex')\n",
    "\n",
    "print(f'[Baseline] The equal opportunity difference is {eq_opp_diff: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "This value implies that the model benefits the unprivileged group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e997ef",
   "metadata": {},
   "source": [
    "Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fair_metrics([0, 0, 0], '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1c56a",
   "metadata": {},
   "source": [
    "This metrics plot shows only the baseline model, as we have not yet corrected for fairness. The value we are most concerned about correcting is the generalized entropy error. However, we know this will yield a tradeoff with the group metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c2ac7",
   "metadata": {},
   "source": [
    "# Pre-Processing Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Choosing logistic, can choose other models \n",
    "##analyze coefficients to understand the which parts play a role in the analysis su\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "rew = ReweighingMeta(estimator=lr, reweigher=Reweighing('sex'))\n",
    "rew.fit(X_train, y_train)\n",
    "y_pred_REW = rew.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815dde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_REW = accuracy_score(y_test, y_pred_REW)\n",
    "print(f'[Reweighting] The test accuracy of the algorithm is: {acc_REW: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a502e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred_REW)\n",
    "make_confusion_matrix(cf_matrix, \"[Reweighting]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6753c",
   "metadata": {},
   "source": [
    "These precision, recall and accuracy values are not too different than the baseline model. They are only slightly lower than the original values. \n",
    "\n",
    "Accuracy: The reweighted model correctly predicts the score (high or low) 58.9% of the time.\n",
    "\n",
    "Precision: 55.7% of the reweighted model’s predicted high scores were actually high scores.\n",
    "\n",
    "Recall: The reweighted model identifies 47.6% of the actual high scores.\n",
    "\n",
    "The F1 score is slightly lower than the baseline model, reflecting the slightly lower values of precision and recall. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e5f87",
   "metadata": {},
   "source": [
    "Reweighting the model appears to have closed the gaps between the male and female scores for accuracy and recall. However, there is a greater discrepancy in the precision scores for males and females. Whereas before approximately 50% of the predicted high scores for males were correct, now closer to 40% are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22817bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_group(y_test, y_pred_REW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_par_diff_RW = statistical_parity_difference(y_test, y_pred_REW, prot_attr='sex')\n",
    "print(f'[Reweighting] The statistical parity difference is {stat_par_diff_RW: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe735e1",
   "metadata": {},
   "source": [
    "The value is close to 0, and implying higher benefit to the unprivileged group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01191087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalance the dataset using the algorithm in the paper\n",
    "# train the model\n",
    "# evalute model on the same metrics\n",
    "eq_opp_diff_RW = equal_opportunity_difference(y_test, y_pred_REW, prot_attr='sex')\n",
    "\n",
    "print(f'[Reweighting] The equal opportunity difference is {eq_opp_diff_RW: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94929b96",
   "metadata": {},
   "source": [
    "The value is close to 0, and implying higher benefit to the unprivileged group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_entr_error_RW = generalized_entropy_error(y_test, y_pred_REW, alpha=1)\n",
    "\n",
    "\n",
    "print(f'[Reweighting] The generalized entropy error is {gen_entr_error_RW: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c74717",
   "metadata": {},
   "source": [
    "The generalized entropy error is still high, as it only went down by 0.01. Therefore, the model is still far from individual fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4381d7",
   "metadata": {},
   "source": [
    "When we reweigh the sensitive variables the model gets better for group metrics, parity and equal opportunity difference, going down to 0.04 and implying benefit to the unprivileged group. However, the individual metric gets worse, going up to 0.325, implying that the model is still far from fair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57535d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fair_metrics([stat_par_diff_RW, eq_opp_diff_RW, gen_entr_error_RW], 'Reweighting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbfdb9",
   "metadata": {},
   "source": [
    "# Post-Processing: Control Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e885e2",
   "metadata": {},
   "source": [
    "We could not get our in-processing methods to work, which would have corrected the learning algorithm. We instead jump to post-processing technique where transforms model outputs in order to correct fairness later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a507ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "# train model\n",
    "# add the reject opinion based classification algorithm\n",
    "# evaluate on fairness metrics\n",
    "\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "\n",
    "pp = CalibratedEqualizedOdds('sex', cost_constraint='fnr', random_state=1234567)\n",
    "ceo = PostProcessingMeta(estimator=lr, postprocessor=pp, random_state=1234567)\n",
    "ceo.fit(X_train, y_train)\n",
    "y_pred_CEO = ceo.predict(X_test)\n",
    "y_proba_CEO = ceo.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e97596",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_CEO = accuracy_score(y_test, y_pred_CEO)\n",
    "print(f'[Calibrated Equalized Odds] The test accuracy of the algorithm is: {acc_CEO: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32300c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred_CEO)\n",
    "make_confusion_matrix(cf_matrix, \"[Calibrated Equalized Odds]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a12e0",
   "metadata": {},
   "source": [
    "We can see that we have a very low recall rate, demonstrating that of the positive guesses, 3% are actually correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_par_diff_CEO = statistical_parity_difference(y_test, y_pred_CEO, prot_attr='sex')\n",
    "\n",
    "print(f'[Calibrated Equalized Odds] The statistical parity difference is {stat_par_diff_CEO: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_opp_diff_CEO = equal_opportunity_difference(y_test, y_pred_CEO, prot_attr='sex')\n",
    "\n",
    "print(f'[Calibrated Equalized Odds] The equal opportunity difference is {eq_opp_diff_CEO: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_entr_error_CEO = generalized_entropy_error(y_test, y_pred_CEO, alpha=1)\n",
    "\n",
    "\n",
    "print(f'[Calibrated Equalized Odds] The generalized entropy error is {gen_entr_error_CEO: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2277410",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fair_metrics([stat_par_diff_CEO, eq_opp_diff_CEO, gen_entr_error_CEO], 'Calibrated Equalized Odds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c27128",
   "metadata": {},
   "source": [
    "All three metrics get much worse. The group metrics become negative and further from 0, implying a greater benefit to the privileged group. The individual metric also gets worse, almost doubling, to indicate that the post-processing method makes the model more unfair. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
