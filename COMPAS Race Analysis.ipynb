{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPAS Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amrita Acharya, Dianne Caravela, Elisabeth Nesmith, Emma Kornberg, Eunice Kim with Women At the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aif360\n",
      "  Using cached aif360-0.4.0-py3-none-any.whl (175 kB)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360) (3.2.1)\n",
      "Collecting tempeh\n",
      "  Using cached tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
      "Collecting scikit-learn>=0.22.1\n",
      "  Using cached scikit_learn-1.0.2-cp37-cp37m-macosx_10_13_x86_64.whl (7.8 MB)\n",
      "Collecting pandas>=0.24.0\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-macosx_10_9_x86_64.whl (10.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.0 MB 3.8 MB/s ta 0:00:01�██▊ | 9.6 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360) (1.21.5)\n",
      "Collecting scipy<1.6.0,>=1.2.0\n",
      "  Using cached scipy-1.5.4-cp37-cp37m-macosx_10_9_x86_64.whl (28.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360) (0.10.0)\n",
      "Processing /Users/amritaacharya/Library/Caches/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f/memory_profiler-0.60.0-py3-none-any.whl\n",
      "Collecting shap\n",
      "  Using cached shap-0.40.0-cp37-cp37m-macosx_10_9_x86_64.whl (433 kB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-7.1.1-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 26.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 32.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib->aif360) (1.15.0)\n",
      "Collecting psutil\n",
      "  Using cached psutil-5.9.0-cp37-cp37m-macosx_10_9_x86_64.whl (238 kB)\n",
      "Collecting tqdm>4.25.0\n",
      "  Using cached tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "Collecting packaging>20.9\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting slicer==0.0.7\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting numba\n",
      "  Using cached numba-0.55.1-cp37-cp37m-macosx_10_14_x86_64.whl (2.3 MB)\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting importlib-metadata>=0.12; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting attrs>=19.2.0\n",
      "  Using cached attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "\u001b[K     |████████████████████████████████| 149 kB 34.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Using cached llvmlite-0.38.0-cp37-cp37m-macosx_10_9_x86_64.whl (25.5 MB)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from numba->shap->tempeh->aif360) (39.0.1)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
      "Installing collected packages: psutil, memory-profiler, tqdm, packaging, slicer, pytz, pandas, cloudpickle, joblib, threadpoolctl, scipy, scikit-learn, llvmlite, numba, shap, iniconfig, py, typing-extensions, zipp, importlib-metadata, pluggy, tomli, attrs, pytest, urllib3, idna, certifi, charset-normalizer, requests, tempeh, aif360\n",
      "Successfully installed aif360-0.4.0 attrs-21.4.0 certifi-2021.10.8 charset-normalizer-2.0.12 cloudpickle-2.0.0 idna-3.3 importlib-metadata-4.11.3 iniconfig-1.1.1 joblib-1.1.0 llvmlite-0.38.0 memory-profiler-0.60.0 numba-0.55.1 packaging-21.3 pandas-1.1.5 pluggy-1.0.0 psutil-5.9.0 py-1.11.0 pytest-7.1.1 pytz-2022.1 requests-2.27.1 scikit-learn-1.0.2 scipy-1.5.4 shap-0.40.0 slicer-0.0.7 tempeh-0.1.12 threadpoolctl-3.1.0 tomli-2.0.1 tqdm-4.63.0 typing-extensions-4.1.1 urllib3-1.26.9 zipp-3.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting fairlearn\n",
      "  Using cached fairlearn-0.7.0-py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from fairlearn) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from fairlearn) (1.0.2)\n",
      "Requirement already satisfied: pandas>=0.25.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from fairlearn) (1.1.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from fairlearn) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn>=0.22.1->fairlearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn>=0.22.1->fairlearn) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas>=0.25.1->fairlearn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas>=0.25.1->fairlearn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
      "Installing collected packages: fairlearn\n",
      "Successfully installed fairlearn-0.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: aif360[AdversarialDebiasing] in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360[AdversarialDebiasing]) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360[AdversarialDebiasing]) (3.2.1)\n",
      "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360[AdversarialDebiasing]) (1.5.4)\n",
      "Requirement already satisfied: tempeh in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360[AdversarialDebiasing]) (0.1.12)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360[AdversarialDebiasing]) (1.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from aif360[AdversarialDebiasing]) (1.1.5)\n",
      "Collecting tensorflow>=1.13.1; extra == \"adversarialdebiasing\"\n",
      "  Using cached tensorflow-2.8.0-cp37-cp37m-macosx_10_14_x86_64.whl (217.4 MB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360[AdversarialDebiasing]) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360[AdversarialDebiasing]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360[AdversarialDebiasing]) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->aif360[AdversarialDebiasing]) (1.2.0)\n",
      "Requirement already satisfied: pytest in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tempeh->aif360[AdversarialDebiasing]) (7.1.1)\n",
      "Requirement already satisfied: shap in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tempeh->aif360[AdversarialDebiasing]) (0.40.0)\n",
      "Requirement already satisfied: memory-profiler in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tempeh->aif360[AdversarialDebiasing]) (0.60.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tempeh->aif360[AdversarialDebiasing]) (2.27.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn>=0.22.1->aif360[AdversarialDebiasing]) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn>=0.22.1->aif360[AdversarialDebiasing]) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas>=0.24.0->aif360[AdversarialDebiasing]) (2022.1)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.6.0-cp37-cp37m-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "Processing /Users/amritaacharya/Library/Caches/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-macosx_10_9_x86_64.whl (13.0 MB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.0-cp37-cp37m-macosx_10_9_x86_64.whl (34 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp37-cp37m-macosx_10_9_x86_64.whl (960 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.24.0-cp37-cp37m-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.44.0-cp37-cp37m-macosx_10_10_x86_64.whl (4.2 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (39.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (1.15.0)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=1.13.1; extra == \"adversarialdebiasing\"->aif360[AdversarialDebiasing]) (4.1.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytest->tempeh->aif360[AdversarialDebiasing]) (2.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytest->tempeh->aif360[AdversarialDebiasing]) (21.4.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytest->tempeh->aif360[AdversarialDebiasing]) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytest->tempeh->aif360[AdversarialDebiasing]) (4.11.3)\n",
      "Requirement already satisfied: py>=1.8.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytest->tempeh->aif360[AdversarialDebiasing]) (1.11.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytest->tempeh->aif360[AdversarialDebiasing]) (21.3)\n",
      "Requirement already satisfied: iniconfig in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pytest->tempeh->aif360[AdversarialDebiasing]) (1.1.1)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from shap->tempeh->aif360[AdversarialDebiasing]) (2.0.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from shap->tempeh->aif360[AdversarialDebiasing]) (4.63.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from shap->tempeh->aif360[AdversarialDebiasing]) (0.0.7)\n",
      "Requirement already satisfied: numba in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from shap->tempeh->aif360[AdversarialDebiasing]) (0.55.1)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from memory-profiler->tempeh->aif360[AdversarialDebiasing]) (5.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->tempeh->aif360[AdversarialDebiasing]) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->tempeh->aif360[AdversarialDebiasing]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->tempeh->aif360[AdversarialDebiasing]) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->tempeh->aif360[AdversarialDebiasing]) (3.3)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 4.5 MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->tempeh->aif360[AdversarialDebiasing]) (3.7.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from numba->shap->tempeh->aif360[AdversarialDebiasing]) (0.38.0)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[31mERROR: tensorboard 2.8.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.0.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: cached-property, h5py, termcolor, wheel, astunparse, libclang, keras, wrapt, protobuf, tensorflow-io-gcs-filesystem, keras-preprocessing, flatbuffers, absl-py, tf-estimator-nightly, grpcio, opt-einsum, gast, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, tensorboard-data-server, oauthlib, requests-oauthlib, google-auth-oauthlib, werkzeug, markdown, tensorboard-plugin-wit, tensorboard, google-pasta, tensorflow\n"
     ]
    }
   ],
   "source": [
    "##Install packages \n",
    "!pip install aif360;\n",
    "!pip install fairlearn;\n",
    "!pip install 'aif360[AdversarialDebiasing]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Install packages to fetch data \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.sklearn.datasets import fetch_compas\n",
    "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
    "\n",
    "from aif360.sklearn.preprocessing import ReweighingMeta\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, average_odds_error, generalized_fpr, average_odds_difference\n",
    "from aif360.sklearn.metrics import generalized_fnr, difference, statistical_parity_difference, equal_opportunity_difference, generalized_entropy_error\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in data\n",
    "## In machine learning tasks, specifically with supervised learning, you have features and labels. \n",
    "## The features are the descriptive attributes (they are defined as X), and the label (y) is what you're attempting to predict or forecast\n",
    "\n",
    "X, y = fetch_compas()\n",
    "print(f'There are {X.shape[0]} entries and {X.shape[1]} features')\n",
    "X.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## because our analysis is mainly focusing on how the algorithm treats white and Black people differently, we are\n",
    "## dropping the rows of data where race != Caucasian or African American\n",
    "## question: do we need to do this for y as well?\n",
    "X_new = X[(X.race == \"Caucasian\") | (X.race == \"African-American\")]\n",
    "print(f'There are {X_new.shape[0]} entries and {X_new.shape[1]} features')\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unused race categories\n",
    "# list of categories to be removed\n",
    "X_new[\"race\"] = X_new[\"race\"].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_new = y[(y.index.get_level_values(2) == \"Caucasian\") | (y.index.get_level_values(2) == \"African-American\")]\n",
    "y_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for visualising the confusion matrix and other statistics\n",
    "# https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n",
    "\n",
    "def make_confusion_matrix(cf_matrix, model):\n",
    "  group_names = [\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\n",
    "  group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                  cf_matrix.flatten()]\n",
    "  group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "  group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "  group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf_matrix.flatten()]\n",
    "  group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "  box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "  box_labels = np.asarray(box_labels).reshape(cf_matrix.shape[0],cf_matrix.shape[1])\n",
    "\n",
    "\n",
    "  # add more statistics\n",
    "  accuracy  = np.trace(cf_matrix) / float(np.sum(cf_matrix))\n",
    "  precision = cf_matrix[1,1] / sum(cf_matrix[:,1])\n",
    "  recall    = cf_matrix[1,1] / sum(cf_matrix[1,:])\n",
    "  f1_score  = 2*precision*recall / (precision + recall)\n",
    "  stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "      accuracy,precision,recall,f1_score)\n",
    "\n",
    "\n",
    "  categories=[\"Survived\", \"Recidivated\"]\n",
    "  sns.heatmap(cf_matrix,annot=box_labels,fmt=\"\",cmap='Purples',xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label' + stats_text)\n",
    "  plt.title(f\"Confusion matrix and statistics for the {model} model\");\n",
    "\n",
    "## defining function for displaying metrics of training and test data by sex \n",
    "def metrics_per_group(y_test, y_pred):\n",
    "\t# y true per group\n",
    "\ty_test_white = y_test.loc[y_test.index.get_level_values(2) == 1]\n",
    "\ty_test_black = y_test.loc[y_test.index.get_level_values(2) == 0]\n",
    "\n",
    "\t# y_pred per group\n",
    "\ty_pred_white = y_pred[y_test.index.get_level_values(2) == 1]\n",
    "\ty_pred_black = y_pred[y_test.index.get_level_values(2) == 0]\n",
    "\n",
    "\t# metrics\n",
    "\tscores = []\n",
    "\tscores.append(accuracy_score(y_test, y_pred))\n",
    "\tscores.append(recall_score(y_test, y_pred))\n",
    "\tscores.append(precision_score(y_test, y_pred))\n",
    "\n",
    "\tscores.append(accuracy_score(y_test_black, y_pred_black))\n",
    "\tscores.append(recall_score(y_test_black, y_pred_black))\n",
    "\tscores.append(precision_score(y_test_black, y_pred_black))\n",
    "\n",
    "\tscores.append(accuracy_score(y_test_white, y_pred_white))\n",
    "\tscores.append(recall_score(y_test_white, y_pred_white))\n",
    "\tscores.append(precision_score(y_test_white, y_pred_white))\n",
    "\n",
    "\tattribute = [\"all\"]*3 + [\"black\"] *3 + [\"white\"] *3\n",
    "\tmetric = [\"accuracy\", \"recall\", \"precision\"] * 3\n",
    "\t  \n",
    "\t# dictionary of lists \n",
    "\tdict = {'race': attribute, 'metrics': metric, 'score': scores} \n",
    "\t    \n",
    "\tdf = pd.DataFrame(dict)\n",
    "\n",
    "\tsns.barplot(x = \"metrics\", y = \"score\", hue = \"race\", data = df, palette = ['#dfcd1a', '#9d0677', '#236c48'])\n",
    "\tplt.title(\"Performance metrics by groups\")\n",
    " \n",
    "\n",
    "def plot_fair_metrics(fair_metrics_mitigated, model): \n",
    "  cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'generalized_entropy']\n",
    "  obj_fairness = [[0,0,1]]\n",
    "\n",
    "  # row for objectives    \n",
    "  fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "      \n",
    "  # row for baseline model\n",
    "  fair_metrics.loc['Baseline Model'] = [stat_par_diff, eq_opp_diff, gen_entr_error]\n",
    "\n",
    "  # row for mitigated bias\n",
    "  fair_metrics.loc[model] = fair_metrics_mitigated\n",
    "\n",
    "\n",
    "  metrics_len = len(cols)\n",
    "\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(20,4), ncols=metrics_len, nrows=1)\n",
    "\n",
    "  plt.subplots_adjust(\n",
    "      left    =  0.125, \n",
    "      bottom  =  0.1, \n",
    "      right   =  0.9, \n",
    "      top     =  0.9, \n",
    "      wspace  =  .5, \n",
    "      hspace  =  1.1\n",
    "  )\n",
    "\n",
    "  y_title_margin = 1.2\n",
    "\n",
    "  plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "  sns.set(style=\"dark\")\n",
    "\n",
    "  cols = fair_metrics.columns.values\n",
    "  obj = fair_metrics.loc['objective']\n",
    "  size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "  rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "  bottom = [-1,-1,-1,0,0]\n",
    "  top = [1,1,1,2,1]\n",
    "  bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "  for i in range(0,metrics_len):\n",
    "      plt.subplot(1, metrics_len, i+1)\n",
    "      ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "      \n",
    "      for j in range(0,len(fair_metrics)-1):\n",
    "          a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "          marg = -0.2 if val < 0 else 0.1\n",
    "          ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "      plt.ylim(bottom[i], top[i])\n",
    "      plt.setp(ax.patches, linewidth=0)\n",
    "      ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "      plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "      plt.title(cols[i])\n",
    "      ax.set_ylabel('')    \n",
    "      ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new.index = pd.MultiIndex.from_arrays(X_new.index.codes, names=X_new.index.names)\n",
    "y_new.index = pd.MultiIndex.from_arrays(y_new.index.codes, names=y_new.index.names)\n",
    "# 0 is Male, 1 is Female\n",
    "# 0 is African American, 2 is Caucasian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set caucasian equal to 1 instead of 2\n",
    "X_new = X_new.rename(index={2: 1}, level='race')\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target class to 0/1 \n",
    "y_new = pd.Series(y_new.factorize(sort=True)[0], index=y_new.index)\n",
    "# set caucasian equal to 1 instead of 2\n",
    "y_new = y_new.rename(index={2: 1}, level='race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = X_new.copy()\n",
    "df_viz['race'] = X_new['race'].replace({1.0: 'Caucasian', 0.0: 'African-American'})\n",
    "df_viz['two_year_recid'] = y_new.replace({1:'Recidivated', 0: 'Survived'})\n",
    "df_viz.index = df_viz.index.droplevel('race')\n",
    "\n",
    "purple = '#9d0677'\n",
    "green = '#30875c'\n",
    "workshop_palette = [purple, green]\n",
    "df_viz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of recividism\n",
    "sns.countplot(x='two_year_recid', data=df_viz, palette=workshop_palette)\n",
    "plt.title('Two Year Recidivism Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of race\n",
    "sns.countplot(y=\"race\", data=df_viz, palette=[\"#30875c\"])\n",
    "plt.title('Race Distribution (White and Black individuals only)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age distribution by race\n",
    "ax = sns.kdeplot(x=\"age\", hue=\"race\", data=df_viz);\n",
    "kdeline = ax.lines[0]\n",
    "mean_fem = df_viz.groupby('race').age.median()[0]\n",
    "xs = kdeline.get_xdata()\n",
    "ys = kdeline.get_ydata()\n",
    "height_fem = np.interp(mean_fem, xs, ys)\n",
    "ax.vlines(mean_fem, 0, height_fem, color=purple, ls=':')\n",
    "\n",
    "mean_m = df_viz.groupby('race').age.median()[1]\n",
    "height_m = np.interp(mean_m, xs, ys)\n",
    "ax.vlines(mean_m, 0, height_m, color=green, ls=':')\n",
    "\n",
    "\n",
    "print(df_viz.groupby('race').age.median())\n",
    "\n",
    "plt.title('Distribution of Age by Race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recividism by race\n",
    "by_sex = sns.countplot(x=\"race\", hue=\"two_year_recid\", data=df_viz, palette=workshop_palette)\n",
    "\n",
    "plt.title('Two Year Recidivism by Race')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, random_state=1234567)\n",
    "\n",
    "# one-hoy encode the categorical features\n",
    "data_preproc = make_column_transformer(\n",
    "        (OneHotEncoder(sparse=False, handle_unknown='ignore'), X_train.dtypes == 'category'))\n",
    "\n",
    "X_train = pd.DataFrame(data_preproc.fit_transform(X_train), index=X_train.index)\n",
    "X_test = pd.DataFrame(data_preproc.transform(X_test), index=X_test.index)\n",
    "\n",
    "# to save the information for the column names\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.get_dummies(X_new).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.sklearn.preprocessing import ReweighingMeta, Reweighing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_roc_curve, recall_score, precision_score\n",
    "\n",
    "\n",
    "lr = LogisticRegressionCV(solver='lbfgs')\n",
    "reg = lr.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "acc_base = accuracy_score(y_test, y_pred)\n",
    "print(f'[Baseline] The test accuracy of the algorithm is: {acc_base: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Look at 2nd column of matrix for precision \n",
    "##2nd row of matrix for recall \n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "make_confusion_matrix(cf_matrix, \"[Baseline]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_group(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Black population, the model correctly identifies 70% of people who recidivated. In the white population, the model correctly identifies 20% of people who recidivated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Group fairness) Statistical Parity Difference \n",
    "\n",
    "Computed as the difference of the rate of favorable outcomes (in this case, did not recidivate) received by the unprivileged group to the privileged group. It essentially equalizes the outcomes across the protected and non-protected groups.\n",
    "The ideal value of this metric is 0. Fairness for this metric is between -0.1 and 0.1. A negative value means there is higher benefit for the privileged group (in this case, white defendants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stat_par_diff = statistical_parity_difference(y_test, prot_attr='race', pos_label = 0)\n",
    "\n",
    "print(f'[Baseline] The statistical parity difference is {stat_par_diff: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized entropy error \n",
    "\n",
    "Generalized entropy index is proposed as a unified individual and group fairness measure. It measures the inequality in benefit allocation for individuals.\n",
    "A value of 0 implies perfect fairness.\n",
    "Fairness is indicated by lower scores, higher scores are problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_entr_error = generalized_entropy_error(y_test, y_pred, alpha=1, pos_label = 0)\n",
    "\n",
    "print(f'[Baseline] The generalized entropy error is {gen_entr_error: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Group fairness) Equal Opportunity Difference \n",
    "\n",
    "This metric is computed as the difference of true positive rates between the unprivileged and the privileged groups. The true positive rate is the ratio of true positives to the total number of actual positives for a given group.\n",
    "The ideal value is 0. A value of < 0 implies higher benefit for the privileged group and a value > 0 implies higher benefit for the unprivileged group.\n",
    "Fairness for this metric is between -0.1 and 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_opp_diff = equal_opportunity_difference(y_test, y_pred, prot_attr='race', pos_label = 0)\n",
    "\n",
    "print(f'[Baseline] The equal opportunity difference is {eq_opp_diff: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fair_metrics([0, 0, 0], '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(solver='lbfgs')\n",
    "rew = ReweighingMeta(estimator=lr, reweigher=Reweighing('race'))\n",
    "rew.fit(X_train, y_train)\n",
    "y_pred_REW = rew.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_REW = accuracy_score(y_test, y_pred_REW)\n",
    "print(f'[Reweighting] The test accuracy of the algorithm is: {acc_REW: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred_REW)\n",
    "make_confusion_matrix(cf_matrix, \"[Reweighting]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_group(y_test, y_pred_REW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_par_diff_RW = statistical_parity_difference(y_test, y_pred_REW, prot_attr='race', pos_label = 0)\n",
    "print(f'[Reweighting] The statistical parity difference is {stat_par_diff_RW: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large improvement over our baseline model, which was -0.14. It still implies a slight benefit for white individuals, but it is in the range of -0.1 and 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_opp_diff_RW = equal_opportunity_difference(y_test, y_pred_REW, prot_attr='race', pos_label = 0)\n",
    "\n",
    "print(f'[Reweighting] The equal opportunity difference is {eq_opp_diff_RW: .2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also an improvement from the baseline, as it is now between -0.1 and 0.1. It also now implies a slight benefit for Black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_entr_error_RW = generalized_entropy_error(y_test, y_pred_REW, alpha=1, pos_label = 0)\n",
    "\n",
    "\n",
    "print(f'[Reweighting] The generalized entropy error is {gen_entr_error_RW: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a very slight improvement from 0.24 to 0.23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fair_metrics([stat_par_diff_RW, eq_opp_diff_RW, gen_entr_error_RW], 'Reweighting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = X_train.copy()\n",
    "df_train\n",
    "df_train[\"two_year_recid\"] = y_train\n",
    "df_train.rename(columns={6:'race'}, inplace=True)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "df_test = X_test.copy()\n",
    "df_test[\"two_year_recid\"] = y_test\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_test.rename(columns={6:'race'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BLD = BinaryLabelDataset(favorable_label='0',\n",
    "                                unfavorable_label='1',\n",
    "                                df=df_train,\n",
    "                                label_names=['two_year_recid'],\n",
    "                                protected_attribute_names=['race'])\n",
    "\n",
    "test_BLD = BinaryLabelDataset(favorable_label='0',\n",
    "                                unfavorable_label='1',\n",
    "                                df=df_test,\n",
    "                                label_names=['two_year_recid'],\n",
    "                                protected_attribute_names=['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = MetaFairClassifier(tau=0.8, sensitive_attr='race', type='fdr', seed=1234567)\n",
    "\n",
    "meta.fit(train_BLD)\n",
    "#y_pred_META = meta.predict(test_BLD)\n",
    "#y_pred_META = y_pred_META.labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_AD = accuracy_score(y_test, y_pred_META)\n",
    "print(f'[ Meta-Classification] The test accuracy of the algorithm is: {acc_AD: .2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "\n",
    "pp = CalibratedEqualizedOdds('race', cost_constraint='fnr', random_state=1234567)\n",
    "ceo = PostProcessingMeta(estimator=lr, postprocessor=pp, random_state=1234567)\n",
    "ceo.fit(X_train, y_train)\n",
    "y_pred_CEO = ceo.predict(X_test)\n",
    "y_proba_CEO = ceo.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_CEO = accuracy_score(y_test, y_pred_CEO)\n",
    "print(f'[Calibrated Equalized Odds] The test accuracy of the algorithm is: {acc_CEO: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred_CEO)\n",
    "make_confusion_matrix(cf_matrix, \"[Calibrated Equalized Odds]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_par_diff_CEO = statistical_parity_difference(y_test, y_pred_CEO, prot_attr='race', pos_label = 0)\n",
    "\n",
    "print(f'[Calibrated Equalized Odds] The statistical parity difference is {stat_par_diff_CEO: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_opp_diff_CEO = equal_opportunity_difference(y_test, y_pred_CEO, prot_attr='race', pos_label = 0)\n",
    "\n",
    "print(f'[Calibrated Equalized Odds] The equal opportunity difference is {eq_opp_diff_CEO: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_entr_error_CEO = generalized_entropy_error(y_test, y_pred_CEO, alpha=1, pos_label = 0)\n",
    "\n",
    "print(f'[Calibrated Equalized Odds] The generalized entropy error is {gen_entr_error_CEO: .2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fair_metrics([stat_par_diff_CEO, eq_opp_diff_CEO, gen_entr_error_CEO], 'Calibrated Equalized Odds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
